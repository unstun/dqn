2 files changed
+81
-30


infer.py
+6
-5
                    (float(gpx), float(gpy)),
                    radius=float(tol),
                    fill=False,
                    edgecolor="red",
                    linestyle="--",
                    linewidth=1.0,
                    alpha=0.7,
                )
            )

        env_paths = paths_for_plot.get((env_name, int(run_idx)), {})
        for algo_name, trace in env_paths.items():
                    (float(gpx), float(gpy)),
                    radius=float(tol),
                    fill=False,
                    edgecolor="crimson",
                    linestyle="--",
                    linewidth=1.8,
                    alpha=0.95,
                    zorder=6,
                )
            )

        env_paths = paths_for_plot.get((env_name, int(run_idx)), {})
        for algo_name, trace in env_paths.items():
env.py
+75
-25
        delta_dot_rad_s: np.ndarray,
        a_m_s2: np.ndarray,
        horizon_steps: int,
    ) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        h = max(1, int(horizon_steps))
        delta_dot = np.asarray(delta_dot_rad_s, dtype=np.float64).reshape(-1)
        accel = np.asarray(a_m_s2, dtype=np.float64).reshape(-1)

        min_od = np.full((n,), float("inf"), dtype=np.float64)
        coll = np.zeros((n,), dtype=np.bool_)
        for _ in range(h):
            x, y, psi, v, delta = self._bicycle_integrate_one_step_vec(
                x_m=x,
                y_m=y,
                psi_rad=psi,
                delta_dot_rad_s=delta_dot,
                a_m_s2=accel,
            )
            od, coll_step = self._od_and_collision_at_pose_m_vec(x, y, psi)
            min_od = np.minimum(min_od, od)
            coll |= coll_step

        return x, y, psi, v, min_od, coll

    def _fallback_action_short_rollout(
        self,
        min_od_thr = float(min_od_m)
        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        x, y, psi, _v, min_od, coll = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,

        ok = (~coll) & (min_od >= float(min_od_thr)) & np.isfinite(cost1)
        if bool(ok.any()):
            idx = np.nonzero(ok)[0]
            costs = cost1[idx]
            ods = min_od[idx]
            best_cost = float(np.min(costs))
        h = max(1, int(horizon_steps))
        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        x, y, psi, v, min_od, coll = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,
        a_id: int,
        *,
        horizon_steps: int,
    ) -> tuple[float, float, float, bool]:
        """Simulate a constant discrete action for a short horizon.

        Returns: (cost_to_go_end, v_end, min_od_over_horizon, collision_over_horizon).
        """

        h = max(1, int(horizon_steps))
        v = float(self._v_m_s)
        delta = float(self._delta_rad)

        min_od = float("inf")
        for _ in range(h):
            x, y, psi, v, delta = bicycle_integrate_one_step(
            od, coll = self._od_and_collision_at_pose_m(x, y, psi)
            min_od = min(float(min_od), float(od))
            if coll:
                return float("inf"), float(v), float(min_od), True

        cost = float(self._cost_to_goal_pose_m(x, y, psi))
        return float(cost), float(v), float(min_od), False

    def is_action_safe(
        self,
        horizon_steps: int = 10,
        min_od_m: float = 0.0,
    ) -> bool:
        _cost, _v, min_od, coll = self._rollout_constant_action_metrics(int(a_id), horizon_steps=int(horizon_steps))
        if bool(coll):
            return False
        return float(min_od) >= float(min_od_m)

        # Progress is judged at the end of the short-horizon constant-action rollout, while safety
        # (collision / clearance) is judged over the same horizon.
        cost1, v_end, min_od, coll = self._rollout_constant_action_metrics(int(a_id), horizon_steps=int(horizon_steps))
        if bool(coll):
            return False
        if float(min_od) < float(min_od_m):
            return False
        if not math.isfinite(cost1):
            return False
        if float(cost0 - cost1) >= float(min_progress_m):
            return True

        # Allow backing up / reversing as long as the rollout is safe. This helps the
        # discrete-action RL policies escape local traps in narrow corridors.
        if bool(allow_reverse) and float(v_end) < -1e-6:
            return True
        return False

    def safe_action_mask(
        min_od_thr = float(min_od_m)
        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        _x, _y, _psi, _v, min_od, coll = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,

        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        x, y, psi, v_end, min_od, coll = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,
        cost1 = self._cost_to_goal_pose_m_vec(x, y, psi)

        safe = (~coll) & (min_od >= float(min_od_thr)) & np.isfinite(cost1)
        prog = (float(cost0) - cost1) >= float(min_prog)
        if bool(allow_reverse):
            out = safe & (prog | (v_end < -1e-6))
        else:
            out = safe & prog

        # Fallback: if everything is filtered out, keep the collision-safe actions.
        if bool(fallback_to_safe) and not bool(out.any()):
        delta_dot_rad_s: np.ndarray,
        a_m_s2: np.ndarray,
        horizon_steps: int,
    ) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        h = max(1, int(horizon_steps))
        delta_dot = np.asarray(delta_dot_rad_s, dtype=np.float64).reshape(-1)
        accel = np.asarray(a_m_s2, dtype=np.float64).reshape(-1)

        min_od = np.full((n,), float("inf"), dtype=np.float64)
        coll = np.zeros((n,), dtype=np.bool_)
        reached = np.zeros((n,), dtype=np.bool_)
        active = np.ones((n,), dtype=np.bool_)

        gx_m = float(self.goal_xy[0]) * float(self.cell_size_m)
        gy_m = float(self.goal_xy[1]) * float(self.cell_size_m)
        tol_m = float(self.goal_tolerance_m)

        for _ in range(h):
            if not bool(active.any()):
                break

            x1, y1, psi1, v1, delta1 = self._bicycle_integrate_one_step_vec(
                x_m=x,
                y_m=y,
                psi_rad=psi,
                delta_dot_rad_s=delta_dot,
                a_m_s2=accel,
            )
            # Freeze terminated rollouts (reached/collided) so later steps do not affect masks.
            x = np.where(active, x1, x)
            y = np.where(active, y1, y)
            psi = np.where(active, psi1, psi)
            v = np.where(active, v1, v)
            delta = np.where(active, delta1, delta)

            od, coll_step = self._od_and_collision_at_pose_m_vec(x, y, psi)
            min_od = np.where(active, np.minimum(min_od, od), min_od)
            coll_now = coll_step & active
            coll |= coll_now

            d_goal_m = np.hypot(float(gx_m) - x, float(gy_m) - y)
            reached_now = (d_goal_m <= float(tol_m)) & active & (~coll_now)
            reached |= reached_now

            active &= ~(coll_now | reached_now)

        return x, y, psi, v, min_od, coll, reached

    def _fallback_action_short_rollout(
        self,
        min_od_thr = float(min_od_m)
        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        x, y, psi, _v, min_od, coll, reached = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,

        ok = (~coll) & (min_od >= float(min_od_thr)) & np.isfinite(cost1)
        if bool(ok.any()):
            ok_reached = ok & reached
            idx = np.nonzero(ok_reached if bool(ok_reached.any()) else ok)[0]
            costs = cost1[idx]
            ods = min_od[idx]
            best_cost = float(np.min(costs))
        h = max(1, int(horizon_steps))
        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        x, y, psi, v, min_od, coll, _reached = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,
        a_id: int,
        *,
        horizon_steps: int,
    ) -> tuple[float, float, float, bool, bool]:
        """Simulate a constant discrete action for a short horizon.

        Returns: (cost_to_go_end, v_end, min_od_over_horizon, collision_over_horizon, reached_within_horizon).
        """

        h = max(1, int(horizon_steps))
        v = float(self._v_m_s)
        delta = float(self._delta_rad)

        gx_m = float(self.goal_xy[0]) * float(self.cell_size_m)
        gy_m = float(self.goal_xy[1]) * float(self.cell_size_m)
        tol_m = float(self.goal_tolerance_m)

        min_od = float("inf")
        for _ in range(h):
            x, y, psi, v, delta = bicycle_integrate_one_step(
            od, coll = self._od_and_collision_at_pose_m(x, y, psi)
            min_od = min(float(min_od), float(od))
            if coll:
                return float("inf"), float(v), float(min_od), True, False

            if float(math.hypot(float(gx_m) - float(x), float(gy_m) - float(y))) <= float(tol_m):
                cost = float(self._cost_to_goal_pose_m(x, y, psi))
                return float(cost), float(v), float(min_od), False, True

        cost = float(self._cost_to_goal_pose_m(x, y, psi))
        return float(cost), float(v), float(min_od), False, False

    def is_action_safe(
        self,
        horizon_steps: int = 10,
        min_od_m: float = 0.0,
    ) -> bool:
        _cost, _v, min_od, coll, _reached = self._rollout_constant_action_metrics(
            int(a_id), horizon_steps=int(horizon_steps)
        )
        if bool(coll):
            return False
        return float(min_od) >= float(min_od_m)

        # Progress is judged at the end of the short-horizon constant-action rollout, while safety
        # (collision / clearance) is judged over the same horizon.
        h = max(1, int(horizon_steps))
        cost1, v_end, min_od, coll, reached = self._rollout_constant_action_metrics(int(a_id), horizon_steps=h)
        if bool(coll):
            return False
        if float(min_od) < float(min_od_m):
            return False
        if bool(reached):
            return True
        if not math.isfinite(cost1):
            return False
        if float(cost0 - cost1) >= float(min_progress_m):
            return True

        # Allow backing up / reversing only when no forward-progress actions exist under the same
        # short-horizon constraints. This avoids the degenerate near-goal behavior where the policy
        # keeps selecting reverse/stop-like actions and triggers stuck termination.
        if bool(allow_reverse):
            reverse_v_min = 0.10
            if float(v_end) < -float(reverse_v_min):
                prog_mask = self.admissible_action_mask(
                    horizon_steps=h,
                    min_od_m=float(min_od_m),
                    min_progress_m=float(min_progress_m),
                    fallback_to_safe=False,
                    allow_reverse=False,
                )
                if not bool(prog_mask.any()):
                    return True
        return False

    def safe_action_mask(
        min_od_thr = float(min_od_m)
        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        _x, _y, _psi, _v, min_od, coll, _reached = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,

        delta_dot = self.action_table[:, 0]
        accel = self.action_table[:, 1]
        x, y, psi, v_end, min_od, coll, reached = self._rollout_constant_actions_end_state(
            delta_dot_rad_s=delta_dot,
            a_m_s2=accel,
            horizon_steps=h,
        cost1 = self._cost_to_goal_pose_m_vec(x, y, psi)

        safe = (~coll) & (min_od >= float(min_od_thr)) & np.isfinite(cost1)
        prog = ((float(cost0) - cost1) >= float(min_prog)) | reached
        out = safe & prog
        if bool(allow_reverse) and not bool(out.any()):
            # Only expose reverse actions when no progress actions exist.
            reverse_v_min = 0.10
            out = safe & (v_end < -float(reverse_v_min))

        # Fallback: if everything is filtered out, keep the collision-safe actions.
        if bool(fallback_to_safe) and not bool(out.any()):

====================
Change Summary (by file)

infer.py (plot styling tweaks)

Updated the drawing parameters of the goal tolerance circle:

edgecolor: "red" → "crimson"

linewidth: 1.0 → 1.8

alpha: 0.7 → 0.95

Added zorder=6 (puts the circle on a higher layer so it won’t be hidden by trajectories/other plot elements)

Other parameters (radius, fill, linestyle="--", etc.) remain unchanged.

env.py (short-horizon rollout / safety mask / reverse-action logic refactor)
The core changes fall into three main areas:

A. Improved batch rollout termination: added reached/active, and “freeze” terminated rollouts

_rollout_constant_actions_end_state(...) return values increased from 6 to 7:

Old: return x, y, psi, v, min_od, coll

New: return x, y, psi, v, min_od, coll, reached

New arrays:

reached: whether each action reaches the goal within the horizon (inside goal tolerance)

active: marks rollouts that are still being simulated (not reached and not collided)

Per-step behavior:

Integrate one step only for active rollouts to get x1, y1, psi1, v1, delta1

For inactive rollouts, use np.where to keep prior state (“freeze”), so later steps don’t affect min_od/coll/reached

Update min_od, coll, compute d_goal_m and reached_now

active &= ~(coll_now | reached_now): terminate when collided or reached

B. Single-action rollout metrics now include “reached goal”

_rollout_constant_action_metrics(...) return values increased from 4 to 5:

Old: (cost_to_go_end, v_end, min_od, coll)

New: (cost_to_go_end, v_end, min_od, coll, reached_within_horizon)

If the rollout enters goal tolerance mid-horizon, it returns immediately with reached=True and the current cost.

C. Safety/admissible action filtering changes (especially allow_reverse)

Both is_action_safe(...) and safe_action_mask(...) now use the new reached signal:

If reached is true, the action can be treated as admissible (assuming no collision and clearance constraints are satisfied).

Reverse action policy changed from “allow reverse whenever safe” to a more conservative rule:

New: only expose reverse actions if no forward-progress actions exist under the same short-horizon constraints

Adds reverse_v_min = 0.10 to avoid treating tiny negative velocities as reversing

In safe_action_mask(...):

Progress condition changed from only (cost0 - cost1) >= min_prog
to (cost0 - cost1) >= min_prog OR reached

If allow_reverse=True and out is all false, only output actions that are safe and have v_end < -reverse_v_min (“reverse only as a last resort”)

D. Fallback behavior now prefers actions that reach the goal

In _fallback_action_short_rollout(...), when ok.any():

Adds ok_reached = ok & reached

Prefer selecting the best action among ok_reached; if none reached, fall back to ok

(Note: this summary is based on the diff snippet you provided; the .txt file keeps the original snippet for side-by-side reference.)